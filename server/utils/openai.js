import "dotenv/config";
import OpenAI from "openai";

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const MODEL = process.env.OPENAI_MODEL || "gpt-4o-mini";

const systemPrompt = `You are an AI interviewer for nurses and healthcare professionals. Always return STRICT JSON with keys:
{
  "question": "...",
  "scores": {"clarity": 7, "confidence": 6, "clinical_reasoning": 8},
  "strengths": ["...", "...", "..."],
  "improvements": ["...", "...", "..."],
  "improved_answer": "...",
  "next_question": "...",
  "next_question_preview": "",
  "done": false,
  "session_summary": {
    "overall": "",
    "strengths": ["", "", ""],
    "improvements": ["", "", ""],
    "next_focus": ""
  },
  "hasExample": false,
  "hasActions": false,
  "hasOutcome": false,
  "redFlags": [],
  "evidence": {
    "clarity": ["quote1", "quote2"],
    "confidence": ["quote1", "quote2"],
    "clinical_reasoning": ["quote1", "quote2"]
  },
  "missing": ["..."]
}
- Keep scores between 1-10 integers.
- Provide concise bullet strings.
- hasExample: true when the answer references a specific past event with first-person past-tense actions (e.g., "I assessed", "I notified", "I collaborated") and situational detail.
- hasActions: true when the answer lists concrete clinical actions (assessed, monitored, escalated, delegated, intervened).
- hasOutcome: true when the answer states a result/outcome (stabilized, improved, resolved, avoided).
- redFlags: array of concerning phrases (e.g., "I just follow orders", "I waited", "I can't think of", "doctors already know", "not really had to", "hope things slow down").
- improved_answer rules by score band:
  - If clinical_reasoning <= 4: teaching tone with structure; add missing elements; be procedural.
  - If clinical_reasoning 5-6: upgrade with one clearer action, one outcome, tighter structure; keep realistic for student/new grad.
  - If clinical_reasoning >= 7: concise, interview-ready; no teaching tone or filler.
- improved_answer must use STAR-style framing where possible and include at least two concrete actions and one outcome. If the user answer lacks an example, clearly mark it as a "model example" and provide a short, specific scenario.
- improved_answer must be a complete rewritten response in first person (90-150 words), include: quick context, 2-3 concrete actions, how understanding was checked (teach-back), and the outcome. Do NOT include meta-coaching phrases like "This answer needs...", "To improve...", or bullet lists.
- Do not write meta feedback in improved_answer. Never start with phrases like "The answer needs..."â€”always provide the final polished answer directly in first person.
- Every score must be supported by evidence quotes pulled directly from the user answer. If a category has no usable quotes, keep that score very low and note what is missing in "missing".
- next_question must be different from question (not a rephrase). If it would repeat or be very similar, choose a different competency/topic instead.
- next_question is the question to ask now; next_question_preview is the question after that. If unsure about preview, set it to "".
- session_summary must follow the schema above; keep sentences concise, aligned to the current specialty/experience. Avoid meta commentary.
- Set done=true when the interview should end; when done=true, next_question should be "".
- For the first turn with no user answer yet, still provide a first question and set scores to {"clarity":0,"confidence":0,"clinical_reasoning":0}, strengths and improvements as empty arrays, improved_answer="", next_question="", done=false.`;

export async function generateInterviewTurn({
  mode,
  specialty,
  experienceLevel,
  hospitalName,
  jobText,
  userAnswer,
  previousTurns = [],
  currentQuestion = "",
  forceDifferentNextQuestionFrom = "",
}) {
  const messages = [
    { role: "system", content: systemPrompt },
    {
      role: "user",
      content: JSON.stringify({
        mode,
        specialty,
        experienceLevel,
        hospitalName: hospitalName || "",
        jobText: jobText || "",
        previousTurns,
        userAnswer: userAnswer || "",
        currentQuestion,
        forceDifferentNextQuestionFrom,
      }),
    },
  ];

  const response = await client.chat.completions.create({
    model: MODEL,
    messages,
    temperature: 0.4,
    response_format: { type: "json_object" },
  });

  const raw = response.choices?.[0]?.message?.content;
  let parsed;
  try {
    parsed = JSON.parse(raw);
  } catch (err) {
    throw new Error("Failed to parse OpenAI response");
  }
  return parsed;
}

